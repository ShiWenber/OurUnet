{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集, 加载数据，定义标签，以及进行数据增强\n",
    "from random import shuffle\n",
    "import torch\n",
    "\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file paths or a list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0\n",
    "\n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.unet_model import UNet\n",
    "from utils.dataset import ISBI_Loader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def train_net(net, device, data_path, epochs = 40, batch_size=1, lr = 0.00001):\n",
    "    # 加载训练集\n",
    "    isbi_dataset = ISBI_Loader(data_path)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "    # 定义损失函数RMSprop\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    # 定义Loss算法\n",
    "    criterion = nn.BCEWithLogitsLoss() \n",
    "    # best_loss 统计，初始化为正无穷\n",
    "    best_loss = float('inf')\n",
    "    # 训练epochs次\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        # 按照batch_size进行训练\n",
    "        for image, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # 数据拷贝到GPU\n",
    "            image = image.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "            # 使用网络参数预测\n",
    "            pred = net(image)\n",
    "            # 计算loss\n",
    "            loss = criterion(pred, label)\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, epochs, loss.item()))\n",
    "            # 保存loss最小的模型\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                torch.save(net.state_dict(), 'best_model.pth')\n",
    "            # 更新参数\n",
    "            loss.backward() # TODO 反向传播\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 0.7404\n",
      "Epoch [1/40], Loss: 0.6831\n",
      "Epoch [1/40], Loss: 0.6405\n",
      "Epoch [1/40], Loss: 0.6519\n",
      "Epoch [1/40], Loss: 0.6894\n",
      "Epoch [1/40], Loss: 0.6693\n",
      "Epoch [1/40], Loss: 0.6686\n",
      "Epoch [1/40], Loss: 0.6812\n",
      "Epoch [1/40], Loss: 0.6484\n",
      "Epoch [1/40], Loss: 0.6454\n",
      "Epoch [1/40], Loss: 0.6407\n",
      "Epoch [1/40], Loss: 0.6469\n",
      "Epoch [1/40], Loss: 0.6386\n",
      "Epoch [1/40], Loss: 0.6783\n",
      "Epoch [1/40], Loss: 0.6384\n",
      "Epoch [1/40], Loss: 0.6438\n",
      "Epoch [1/40], Loss: 0.6289\n",
      "Epoch [1/40], Loss: 0.6367\n",
      "Epoch [1/40], Loss: 0.6294\n",
      "Epoch [1/40], Loss: 0.6322\n",
      "Epoch [1/40], Loss: 0.6326\n",
      "Epoch [1/40], Loss: 0.6388\n",
      "Epoch [1/40], Loss: 0.6431\n",
      "Epoch [1/40], Loss: 0.6282\n",
      "Epoch [1/40], Loss: 0.6338\n",
      "Epoch [1/40], Loss: 0.6398\n",
      "Epoch [1/40], Loss: 0.6417\n",
      "Epoch [1/40], Loss: 0.6301\n",
      "Epoch [1/40], Loss: 0.6318\n",
      "Epoch [1/40], Loss: 0.6136\n",
      "Epoch [2/40], Loss: 0.6423\n",
      "Epoch [2/40], Loss: 0.6303\n",
      "Epoch [2/40], Loss: 0.6328\n",
      "Epoch [2/40], Loss: 0.6343\n",
      "Epoch [2/40], Loss: 0.6306\n",
      "Epoch [2/40], Loss: 0.6382\n",
      "Epoch [2/40], Loss: 0.6422\n",
      "Epoch [2/40], Loss: 0.6525\n",
      "Epoch [2/40], Loss: 0.6348\n",
      "Epoch [2/40], Loss: 0.6289\n",
      "Epoch [2/40], Loss: 0.6307\n",
      "Epoch [2/40], Loss: 0.6170\n",
      "Epoch [2/40], Loss: 0.6412\n",
      "Epoch [2/40], Loss: 0.6310\n",
      "Epoch [2/40], Loss: 0.6417\n",
      "Epoch [2/40], Loss: 0.6416\n",
      "Epoch [2/40], Loss: 0.6384\n",
      "Epoch [2/40], Loss: 0.6408\n",
      "Epoch [2/40], Loss: 0.6276\n",
      "Epoch [2/40], Loss: 0.6339\n",
      "Epoch [2/40], Loss: 0.6228\n",
      "Epoch [2/40], Loss: 0.6294\n",
      "Epoch [2/40], Loss: 0.6262\n",
      "Epoch [2/40], Loss: 0.6275\n",
      "Epoch [2/40], Loss: 0.6362\n",
      "Epoch [2/40], Loss: 0.6304\n",
      "Epoch [2/40], Loss: 0.6641\n",
      "Epoch [2/40], Loss: 0.6417\n",
      "Epoch [2/40], Loss: 0.6367\n",
      "Epoch [2/40], Loss: 0.6480\n",
      "Epoch [3/40], Loss: 0.6259\n",
      "Epoch [3/40], Loss: 0.6417\n",
      "Epoch [3/40], Loss: 0.6421\n",
      "Epoch [3/40], Loss: 0.6413\n",
      "Epoch [3/40], Loss: 0.6299\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27386/2386341690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 指定训练集地址，开始训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/train/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_27386/704082352.py\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, device, data_path, epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# 按照batch_size进行训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# 数据拷贝到GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mycode/unet/utils/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# 读取训练图片和标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# 将数据转化为单通道的灰度图\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 选择设备，有cuda用cuda，没有就用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 加载网络，图片单通道1，分类为1。\n",
    "net = UNet(n_channels=1, n_classes=1)\n",
    "# 将网络拷贝到deivce中\n",
    "net.to(device=device)\n",
    "# 指定训练集地址，开始训练\n",
    "data_path = \"data/train/\"\n",
    "train_net(net, device, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from model.unet_model import UNet\n",
    "\n",
    "# 选择设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 加载网络,图片单通道1，分类为1。\n",
    "net = UNet(n_channels=1, n_classes=1)\n",
    "# 载入到device中\n",
    "net.to(device=device)\n",
    "# 加载参数\n",
    "net.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "# 测试\n",
    "net.eval()\n",
    "# 读取图片路径\n",
    "tests_path = glob.glob(\"data_bak/test/*.png\")\n",
    "# 遍历图片\n",
    "for test_path in tests_path:\n",
    "    # 保存结果图片\n",
    "    save_res_path = test_path.split(\".\")[0] + \"_res.png\"\n",
    "    # 读取\n",
    "    img = cv2.imread(test_path)\n",
    "    # 转灰度\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 转为batch为1,通道为1的大小为512*512的数组\n",
    "    img = img.reshape(1,1,img.shape[0], img.shape[1])\n",
    "    # 转tensor\n",
    "    img_tensor = torch.from_numpy(img)\n",
    "    # 转到device中\n",
    "    img_tensor = img_tensor.to(device=device, dtype=torch.float32)\n",
    "    # 预测\n",
    "    pred = net(img_tensor)\n",
    "    # 提取结果\n",
    "    pred = np.array(pred.data.cpu()[0])[0]\n",
    "    # 处理结果\n",
    "    pred[pred >= 0.5] = 255\n",
    "    pred[pred < 0.5] = 0\n",
    "    # 保存图片\n",
    "    cv2.imwrite(save_res_path, pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Oct 18 2022, 18:57:03) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
